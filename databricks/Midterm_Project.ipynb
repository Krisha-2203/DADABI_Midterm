{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "191c92b0-44d3-448c-b4f4-28f76a31a501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "\n",
    "def clean_columns(df):\n",
    "    new_df = df\n",
    "    for old in df.columns:\n",
    "        clean = old.strip()\n",
    "        clean = re.sub(r'[^A-Za-z0-9_]', '_', clean)\n",
    "        clean = re.sub('_+', '_', clean)\n",
    "        new_df = new_df.withColumnRenamed(old, clean)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77fb682a-8ebb-40c9-8d15-f06d8d2f58e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"bronze_chi\",\n",
    "    comment=\"Chicago raw data with cleaned column names\"\n",
    ")\n",
    "def bronze_chi():\n",
    "    return clean_columns(\n",
    "        spark.read.option(\"header\", True)\n",
    "        .csv(\"/Volumes/workspace/damg7370/datastore/Cleaned_Chicago.csv\")\n",
    "    )\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_dal\",\n",
    "    comment=\"Dallas raw data with cleaned column names\"\n",
    ")\n",
    "def bronze_dal():\n",
    "    df = spark.read.option(\"header\", True).csv(\n",
    "        \"/Volumes/workspace/damg7370/datastore/Cleaned_Dallas.csv\"\n",
    "    )\n",
    "    \n",
    "    # Fix weird Dallas column\n",
    "    if \"Description \" in df.columns:\n",
    "        df = df.withColumnRenamed(\"Description \", \"Description_dallas\")\n",
    "\n",
    "    return clean_columns(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6061794f-0f7a-4ab8-8b4d-08b7f297623f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "#              SILVER FINAL (FIXED)\n",
    "# ----------------------------------------------\n",
    "@dlt.table(\n",
    "    name=\"food_silver_final\",\n",
    "    comment=\"Unified Silver layer Chicago + Dallas\"\n",
    ")\n",
    "def food_silver_final():\n",
    "\n",
    "    chi = dlt.read(\"bronze_chi\")\n",
    "    dal = dlt.read(\"bronze_dal\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # CHICAGO STANDARDIZATION\n",
    "    # -------------------------------\n",
    "    chi = (\n",
    "        chi\n",
    "        .withColumnRenamed(\"InspectionID\", \"inspection_id\")\n",
    "        .withColumnRenamed(\"DBA_Name\", \"dba_name\")\n",
    "        .withColumnRenamed(\"AKA_Name\", \"aka_name\")\n",
    "        .withColumnRenamed(\"Facility_Type\", \"facility_type\")\n",
    "        .withColumnRenamed(\"Inspection_Date\", \"inspection_date\")\n",
    "        .withColumnRenamed(\"Inspection_Type\", \"inspection_type\")\n",
    "        .withColumnRenamed(\"Results\", \"inspection_result\")\n",
    "        .withColumnRenamed(\"Violation_Description\", \"violation_description_raw_chi\")\n",
    "        .withColumnRenamed(\"Zip\", \"zip_code\")\n",
    "        .withColumn(\"source_city\", lit(\"Chicago\"))\n",
    "        .withColumn(\"restaurant_name\", coalesce(col(\"dba_name\"), col(\"aka_name\")))\n",
    "        .drop(\"dba_name\", \"aka_name\")\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # DALLAS STANDARDIZATION\n",
    "    # -------------------------------\n",
    "    dal = (\n",
    "        dal\n",
    "        .withColumnRenamed(\"RecordID\", \"inspection_id\")\n",
    "        .withColumnRenamed(\"Inspection_Type\", \"inspection_type\")\n",
    "        .withColumnRenamed(\"Inspection_Date\", \"inspection_date\")\n",
    "        .withColumnRenamed(\"Results\", \"inspection_result\")\n",
    "        .withColumnRenamed(\"Street_Address\", \"address\")\n",
    "        .withColumnRenamed(\"Zip_Code\", \"zip_code\")\n",
    "        .withColumnRenamed(\"Facality_Type\", \"facility_type\")\n",
    "        .withColumnRenamed(\"Violation_desc\", \"violation_description_raw_dal\")\n",
    "        .withColumnRenamed(\"Description_dallas\", \"violation_description_raw_dal_extra\")\n",
    "        .withColumn(\"source_city\", lit(\"Dallas\"))\n",
    "        .withColumn(\"restaurant_name\", col(\"restaurant_name\"))\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # UNION\n",
    "    # -------------------------------\n",
    "    df = chi.unionByName(dal, allowMissingColumns=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # UNIFIED VIOLATION DESCRIPTION\n",
    "    # -------------------------------\n",
    "    df = df.withColumn(\n",
    "        \"violation_description\",\n",
    "        coalesce(\n",
    "            col(\"violation_description_raw_chi\"),\n",
    "            col(\"violation_description_raw_dal\"),\n",
    "            col(\"violation_description_raw_dal_extra\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # FIX VIOLATION CODE\n",
    "    # -------------------------------\n",
    "    from pyspark.sql.window import Window\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"violation_code\",\n",
    "        when(col(\"violation_code\").isNotNull(), col(\"violation_code\"))\n",
    "        .otherwise(\n",
    "            concat(\n",
    "                lit(\"DAL_\"),\n",
    "                lpad(\n",
    "                    row_number().over(Window.orderBy(monotonically_increasing_id())),\n",
    "                    6,\n",
    "                    \"0\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # FINAL CLEANING\n",
    "    # -------------------------------\n",
    "    df = (\n",
    "        df.withColumn(\"zip_code\", regexp_extract(\"zip_code\", r'\\d{5}', 0))\n",
    "          .withColumn(\"inspection_date\", to_date(\"inspection_date\"))\n",
    "          .withColumn(\"latitude\", col(\"Latitude\").cast(\"double\"))\n",
    "          .withColumn(\"longitude\", col(\"Longitude\").cast(\"double\"))\n",
    "          .dropDuplicates([\"inspection_id\"])\n",
    "          .filter(col(\"inspection_id\").isNotNull())\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # NATURAL KEY FOR RESTAURANT\n",
    "    # -------------------------------\n",
    "    df = df.withColumn(\n",
    "        \"restaurant_nk\",\n",
    "        sha2(\n",
    "            concat_ws(\n",
    "                \"||\",\n",
    "                col(\"restaurant_name\"),\n",
    "                col(\"address\"),\n",
    "                col(\"zip_code\")\n",
    "            ),\n",
    "            256\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9e69d9f-d7c8-443b-8d1b-d19df695f38f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ---------------- DIM_DATE ----------------\n",
    "@dlt.table(name=\"dim_date\", comment=\"Date dimension\")\n",
    "def dim_date():\n",
    "    df = dlt.read(\"food_silver_final\")\n",
    "\n",
    "    dim = (\n",
    "        df.select(col(\"inspection_date\").alias(\"full_date\"))\n",
    "          .filter(col(\"full_date\").isNotNull())\n",
    "          .dropDuplicates()\n",
    "          .withColumn(\"date_key\", date_format(\"full_date\", \"yyyyMMdd\").cast(\"int\"))\n",
    "          .withColumn(\"year\", year(\"full_date\"))\n",
    "          .withColumn(\"month\", month(\"full_date\"))\n",
    "          .withColumn(\"day\", dayofmonth(\"full_date\"))\n",
    "          .withColumn(\"quarter\", quarter(\"full_date\"))\n",
    "    )\n",
    "    return dim\n",
    "\n",
    "\n",
    "# ---------------- DIM_CITY ----------------\n",
    "@dlt.table(name=\"dim_city\", comment=\"City dimension\")\n",
    "def dim_city():\n",
    "    df = dlt.read(\"food_silver_final\")\n",
    "    return (\n",
    "        df.select(col(\"source_city\").alias(\"city_name\"))\n",
    "          .dropDuplicates()\n",
    "          .withColumn(\"city_key\", monotonically_increasing_id())\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------- DIM_RESTAURANT ----------------\n",
    "@dlt.table(\n",
    "    name=\"dim_restaurant\",\n",
    "    comment=\"Restaurant dimension with SCD Type-2\"\n",
    ")\n",
    "def dim_restaurant():\n",
    "\n",
    "    df = dlt.read(\"food_silver_final\").select(\n",
    "        col(\"restaurant_name\"),\n",
    "        col(\"address\"),\n",
    "        col(\"zip_code\"),\n",
    "        col(\"license\").alias(\"license_number\"),\n",
    "        col(\"source_city\")\n",
    "    )\n",
    "\n",
    "    # Natural Key for SCD2\n",
    "    df = df.withColumn(\n",
    "        \"restaurant_nk\",\n",
    "        sha2(\n",
    "            concat_ws(\n",
    "                \"||\",\n",
    "                col(\"restaurant_name\"),\n",
    "                col(\"address\"),\n",
    "                col(\"zip_code\")\n",
    "            ), 256\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # SCD2 Metadata\n",
    "    df = (\n",
    "        df.withColumn(\"effective_date\", current_date())\n",
    "          .withColumn(\"end_date\", lit(None).cast(\"date\"))\n",
    "          .withColumn(\"is_current\", lit(True))\n",
    "    )\n",
    "\n",
    "    # Surrogate Key\n",
    "    df = df.withColumn(\"restaurant_key\", monotonically_increasing_id())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- DIM_VIOLATION ----------------\n",
    "@dlt.table(name=\"dim_violation\", comment=\"Violation dimension\")\n",
    "def dim_violation():\n",
    "    df = dlt.read(\"food_silver_final\")\n",
    "    return (\n",
    "        df.select(\"violation_code\", \"violation_description\")\n",
    "          .dropDuplicates()\n",
    "          .withColumn(\"violation_key\", monotonically_increasing_id())\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------- DIM_RESULT ----------------\n",
    "@dlt.table(name=\"dim_result\", comment=\"Inspection result dimension\")\n",
    "def dim_result():\n",
    "    df = dlt.read(\"food_silver_final\")\n",
    "\n",
    "    return (\n",
    "        df.select(col(\"inspection_result\").alias(\"result_name\"))\n",
    "          .dropDuplicates()\n",
    "          .withColumn(\"inspection_result_key\", monotonically_increasing_id())\n",
    "          .withColumn(\n",
    "                \"derived_score\",\n",
    "                when(col(\"result_name\") == \"Pass\", 90)\n",
    "                .when(col(\"result_name\") == \"Pass w/ Conditions\", 80)\n",
    "                .when(col(\"result_name\") == \"Fail\", 70)\n",
    "                .otherwise(60)\n",
    "          )\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------- DIM_TYPE ----------------\n",
    "@dlt.table(name=\"dim_type\", comment=\"Inspection type dimension\")\n",
    "def dim_type():\n",
    "    df = dlt.read(\"food_silver_final\")\n",
    "    return (\n",
    "        df.select(\"inspection_type\")\n",
    "          .dropDuplicates()\n",
    "          .withColumn(\"inspection_type_key\", monotonically_increasing_id())\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------- DIM_FACILITY ----------------\n",
    "@dlt.table(name=\"dim_facility_type\", comment=\"Facility type dimension\")\n",
    "def dim_facility_type():\n",
    "    df = dlt.read(\"food_silver_final\")\n",
    "    return (\n",
    "        df.select(\"facility_type\")\n",
    "          .dropDuplicates()\n",
    "          .withColumn(\"facility_type_key\", monotonically_increasing_id())\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0110aa72-5a1c-47fa-9dce-17027eae4a97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"fact_food_inspection\",\n",
    "    comment=\"Fact table depending ONLY on dimensions (no silver lineage)\"\n",
    ")\n",
    "def fact_food_inspection():\n",
    "\n",
    "    s = (\n",
    "        spark.table(\"workspace.default.food_silver_final\")\n",
    "        .select(\n",
    "            \"inspection_id\",\n",
    "            \"inspection_date\",\n",
    "            \"inspection_type\",\n",
    "            \"inspection_result\",\n",
    "            \"violation_code\",\n",
    "            \"violation_description\",\n",
    "            \"restaurant_nk\",       # <-- REQUIRED FOR JOIN\n",
    "            \"restaurant_name\",\n",
    "            \"address\",\n",
    "            \"zip_code\",\n",
    "            \"facility_type\",\n",
    "            \"source_city\",\n",
    "            \"derivedscore\",\n",
    "            \"risk\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    d_date      = dlt.read(\"dim_date\")\n",
    "    d_city      = dlt.read(\"dim_city\")\n",
    "    d_rest      = dlt.read(\"dim_restaurant\")\n",
    "    d_violation = dlt.read(\"dim_violation\")\n",
    "    d_result    = dlt.read(\"dim_result\")\n",
    "    d_type      = dlt.read(\"dim_type\")\n",
    "    d_fac       = dlt.read(\"dim_facility_type\")\n",
    "\n",
    "    fact = (\n",
    "        s.alias(\"s\")\n",
    "\n",
    "        # DATE DIM\n",
    "        .join(\n",
    "            d_date.alias(\"dd\"),\n",
    "            col(\"s.inspection_date\") == col(\"dd.full_date\"),\n",
    "            \"left\"\n",
    "        )\n",
    "\n",
    "        # CITY DIM\n",
    "        .join(\n",
    "            d_city.alias(\"dc\"),\n",
    "            col(\"s.source_city\") == col(\"dc.city_name\"),\n",
    "            \"left\"\n",
    "        )\n",
    "\n",
    "        # RESTAURANT DIM (SCD2 - NK join)\n",
    "        .join(\n",
    "            d_rest.alias(\"dr\"),\n",
    "            col(\"s.restaurant_nk\") == col(\"dr.restaurant_nk\"),\n",
    "            \"left\"\n",
    "        )\n",
    "\n",
    "        # VIOLATION DIM\n",
    "        .join(\n",
    "            d_violation.alias(\"dv\"),\n",
    "            col(\"s.violation_description\") == col(\"dv.violation_description\"),\n",
    "            \"left\"\n",
    "        )\n",
    "\n",
    "        # RESULT DIM\n",
    "        .join(\n",
    "            d_result.alias(\"res\"),\n",
    "            col(\"s.inspection_result\") == col(\"res.result_name\"),\n",
    "            \"left\"\n",
    "        )\n",
    "\n",
    "        # TYPE DIM\n",
    "        .join(\n",
    "            d_type.alias(\"dt\"),\n",
    "            col(\"s.inspection_type\") == col(\"dt.inspection_type\"),\n",
    "            \"left\"\n",
    "        )\n",
    "\n",
    "        # FACILITY TYPE DIM\n",
    "        .join(\n",
    "            d_fac.alias(\"dfac\"),\n",
    "            col(\"s.facility_type\") == col(\"dfac.facility_type\"),\n",
    "            \"left\"\n",
    "        )\n",
    "\n",
    "        .select(\n",
    "            col(\"s.inspection_id\").alias(\"inspection_key\"),\n",
    "            col(\"dd.date_key\"),\n",
    "            col(\"dc.city_key\"),\n",
    "            col(\"dr.restaurant_key\"),\n",
    "            col(\"dv.violation_key\"),\n",
    "            col(\"res.inspection_result_key\"),\n",
    "            col(\"dt.inspection_type_key\"),\n",
    "            col(\"dfac.facility_type_key\"),\n",
    "            col(\"res.derived_score\"),\n",
    "            col(\"s.risk\"),\n",
    "            col(\"s.source_city\").alias(\"record_source\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fact\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7835855881402650,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Midterm_Project",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}